import gradio as gr
import ollama
import json

model_list = ollama.list()
model_names = [model['model'] for model in model_list['models']]
PROMPT_LIST = []
# è§£æ prompt
with open("prompt.json", "r", encoding="utf-8") as f:
    PROMPT_DICT = json.load(f)
    for key in PROMPT_DICT:
        PROMPT_LIST.append(key)
# PROMPT_SELECT = ["ç¿»è¯‘åŠ©æ‰‹","å‘¨æŠ¥åŠ©æ‰‹"]
# PROMPT_LIST = {
#     "ç¿»è¯‘åŠ©æ‰‹":"ä½ æ˜¯ä¸€ä¸ªå¥½ç”¨çš„ç¿»è¯‘åŠ©æ‰‹ã€‚è¯·å°†æˆ‘çš„ä¸­æ–‡ç¿»è¯‘æˆè‹±æ–‡ï¼Œå°†éä¸­æ–‡çš„ç¿»è¯‘æˆä¸­æ–‡ã€‚æˆ‘å‘ç»™ä½ æ‰€æœ‰çš„è¯éƒ½æ˜¯éœ€è¦ç¿»è¯‘çš„å†…å®¹ï¼Œä½ åªéœ€è¦å›ç­”ç¿»è¯‘ç»“æœã€‚ç¿»è¯‘ç»“æœè¯·ç¬¦åˆä¸­æ–‡çš„è¯­è¨€ä¹ æƒ¯ã€‚",
#     "å‘¨æŠ¥åŠ©æ‰‹":"è¯·å¸®æˆ‘æŠŠä»¥ä¸‹çš„å·¥ä½œå†…å®¹å¡«å……ä¸ºä¸€ç¯‡å®Œæ•´çš„å‘¨æŠ¥ï¼Œç”¨ markdown æ ¼å¼ä»¥åˆ†ç‚¹å™è¿°çš„å½¢å¼è¾“å‡ºï¼š"
# }
def ollama_chat(message, history,model_name,history_flag):
    messages = []
    chat_message = {
        'role': 'user', 
        'content': message
    }
    if history_flag and len(history)>0:
        for element in history:  
            history_user_message = {
                'role': 'user', 
                'content': element[0]
            }
            history_assistant_message = {
                'role': 'assistant', 
                'content': element[1]
            }
            messages.append(history_user_message)
            messages.append(history_assistant_message)   
    messages.append(chat_message)
    stream = ollama.chat(
        model = model_name,
        messages = messages,
        stream=True
    )
    partial_message = ""
    for chunk in stream:
        if len(chunk['message']['content']) != 0:
            partial_message = partial_message + chunk['message']['content']
            yield partial_message
# æ™ºèƒ½ä½“ç”Ÿæˆ
def ollama_prompt(message, history,model_name,prompt_info):
    messages = []
    system_message = {
        'role': 'system', 
        'content': PROMPT_DICT[prompt_info]
    }
    user_message = {
        'role': 'user', 
        'content': message
    }
    messages.append(system_message)
    messages.append(user_message)
    stream = ollama.chat(
        model = model_name,
        messages = messages,       
        stream=True
    )
    partial_message = ""
    for chunk in stream:
        if len(chunk['message']['content']) != 0:
            partial_message = partial_message + chunk['message']['content']
            yield partial_message

with gr.Blocks(title="Ollama WebUI", fill_height=True) as demo:
    with gr.Tab("èŠå¤©"):
        with gr.Row():
            with gr.Column(scale=1):
                model_info = gr.Dropdown(model_names, value="", allow_custom_value=True, label="æ¨¡å‹é€‰æ‹©")
                history_flag = gr.Checkbox(label="å¯ç”¨ä¸Šä¸‹æ–‡")
            with gr.Column(scale=4):
                chat_bot = gr.Chatbot(height=600,render=False)
                text_box = gr.Textbox(scale=4,render=False)
                gr.ChatInterface(
                    fn=ollama_chat,
                    chatbot=chat_bot,
                    textbox=text_box,
                    additional_inputs=[model_info,history_flag],
                    submit_btn="æäº¤",
                    retry_btn="ğŸ”„ é‡è¯•",
                    undo_btn="â†©ï¸ æ’¤æ¶ˆ",
                    clear_btn="ğŸ—‘ï¸ æ¸…é™¤",
                    fill_height=True
                )
    with gr.Tab("æ™ºèƒ½ä½“"):
        with gr.Row():
            with gr.Column(scale=1):
                prompt_model_info = gr.Dropdown(model_names, value="", allow_custom_value=True, label="æ¨¡å‹é€‰æ‹©")
                prompt_info = gr.Dropdown(choices=PROMPT_LIST,value=PROMPT_LIST[0],label="æ™ºèƒ½ä½“é€‰æ‹©",interactive=True)
            with gr.Column(scale=4):
                prompt_chat_bot = gr.Chatbot(height=540,render=False)
                prompt_text_box = gr.Textbox(scale=4,render=False)
                gr.ChatInterface(
                    fn=ollama_prompt,
                    chatbot=prompt_chat_bot,
                    textbox=prompt_text_box,
                    additional_inputs=[prompt_model_info,prompt_info],
                    submit_btn="æäº¤",
                    retry_btn="ğŸ”„ é‡è¯•",
                    undo_btn="â†©ï¸ æ’¤æ¶ˆ",
                    clear_btn="ğŸ—‘ï¸ æ¸…é™¤",
                    fill_height=True
                )
if __name__ == "__main__":
    demo.launch()